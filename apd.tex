
	Sean $X\s \R^n$, $A\s\R^m$ y $\{A(x)\s A\mid x\in X\}$. Nos referiremos a $X$ 
como el 
conjunto de estados, $A$ es el conjunto de control y la familia 
$\{A(x),\ x\in X\}$ 
denota al conjunto de acciones factibles si el sistema está en el estado $x$. 
El 
sistema evoluciona de acuerdo con
\begin{equation}\label{SisteDinam}
	x_{k+1}=f(x_k,a_k), \quad k=0,1,\ldots,N-1,
\end{equation}
donde $x_0$ está dado y $f:X\times A\to X$. 
Decimos que $\{a_0,a_1,\ldots,a_{N-1}\}$ es una sucesión (finita) de acciones 
admisibles si  $a_k\in A(x_k)$ y \eqref{SisteDinam} se satisfacen para todo 
$k=0,1,\ldots,N-1$. Observemos que cada sucesión $\{a_k\}$ de acciones 
admisibles, genera, a través de \eqref{SisteDinam}, una única sucesión de 
estados $\{x_k\}$.

Las sucesiones de acciones admisibles pueden escogerse siguiendo ciertas 
``reglas'', por ejemplo, la acción $a_k$ puede escogerse tomando en cuenta toda 
la {\it historia} 
$(x_0,a_0,\ldots,a_{k-1},x_k)$. De forma precisa, 
$a_k=g_k(x_0,a_0,\ldots,a_{k-1},x_k)$, donde $g_k$ es una función. 
A la sucesión $\pi=\{g_k\}$ se le conoce como {\it política} 
o {\it estrategia}. El algoritmo de programación dinámica, que veremos en la 
Sección 2, genera estrategias que sólo dependen del último estado, es decir, 
$a_k=g_k(x_k)$. A estas estrategias se les conocen como 
{\it estrategias Markovianas}.

El problema de optimización que nos interesa consiste en encontrar una sucesión 
$\pi=\{a_k\}$ de acciones admisibles que minimice el costo  
\begin{equation}\label{FinHorPerInd}
	C_0(x,\pi):=\sum_{k=0}^{N-1}c_k(x_k,a_k) + c_N(x_N),
\end{equation} 
donde $c_k:X\times A\to \mathbb{R}$ para $k\leq N-1$ y $c_N:X\to \mathbb{R}$.
Sea  $\Pi(x)$ el conjunto de todas sucesiones de acciones 
admisibles con la condición inicial $x_0=x$. En términos de la {\it función de 
valor} 
\[
	v(x):=
		\inf_{\pi\in\Pi(x)}C_0(x,\pi),\quad x\in X,
\] 
queremos encontrar $\hat{\pi}$ tal que  $v(x)=C_0(x,\hat{\pi})$ para cada 
estado 
inicial $x$ en $X$. Si el ínfimo se alcanza dentro del conjunto $\Pi(x_0)$, 
reemplazamos $\inf$ por $\min$. 

Para resolver este problema de minimización, asumiendo que existe una solución,
consideremos el siguiente algoritmo.\medskip

\framebox[0.9\textwidth][c]{
\begin{minipage}[c]{0.8\textwidth}
\begin{center}Algoritmo de Programación Dinámica (APD)\end{center}
  \begin{equation}\label{DPAT}
  	J_N(x):=c_N(x),
  \end{equation}
	y para $k=N-1,N-2,\ldots,0$,
  \begin{equation}\label{DPA}
  J_k(x):=\min_{a\in A(x)}\left\{ c_k(x,a) + J_{k+1}(f(x,a))\right\}.
  \end{equation}
\end{minipage}}\medskip

%En esta sección asumimos que las funciones $J_N,\ldots,J_0$, 
%obtenidas a través del 
%APD \eqref{DPAT}--\eqref{DPA}, satisfacen lo siguiente. 
%Se alcanza el mínimo en cada etapa.

%Notemos que, bajo la Hipótesis 2.1, las funciones $h_0,\ldots,h_{N-1}$ 
%generan una %única sucesión de estados $\{x_0,\ldots,x_N\}$ y acciones 
%admisibles $\%
%{a_0,\ldots,a_{N-1}\}$. En efecto, a partir de $x_0$ y $a_0=h_0(x_0)$ 
obtenemos 
%$x_1=f(x_0,h_0(x_0))$ y, de forma recursiva,
%\[ a_k=h_k(x_k),\quad x_{k+1}=f(x_k,h_k(x_k)), \qquad k=1,\ldots,N-1.\] 

\begin{teo}\label{DynProThe} 
	Sean $J_N,\ldots,J_0$ las funciones definidas en \eqref{DPAT}--\eqref{DPA}. 
    Supongamos que para cada $k=0,\ldots,N-1$, existe una función 
    $h_k:X\to A$ tal que $h_k(x)\in A(x)$ y 
    \begin{eqnarray}
 		J_k(x) 
        & = & \min_{a\in A(x)}\left\{ c_k(x,a) + J_{k+1}(f(x,a))\right\}
 		\nonumber\\
       	& = & c_k(x,h_k(x)) + J_{k+1}(f(x,h_k(x))) \label{SelectorHyp}
    \end{eqnarray}
	para todo $x\in X$.  
    Entonces 
    	$\hat{\pi}:=\{h_0(x_0),h_1(x_1),\ldots,h_{N-1}(x_{N-1})\}$ minimiza 		
    \eqref{FinHorPerInd}. Más aún, $J_0$ es igual a la función de valor $v$.
\end{teo}
\begin{proof}
		Sea $\pi'=\{a_0',\ldots,a_{N-1}'\}$ cualquier sucesión de acciones 
		admisibles. Para cada $k=0,\ldots,N-1$, definimos el 
		{\it costo de $k$ hacia adelante}
    \[ 
    	C_k(x,\pi'):= 
		\sum_{j=k}^{N-1}c_j(x_j',a_j')  +  c_N(x_N'),
    \]
	donde $x_k'=x$ y, para $j=k,\ldots,N-1$,
	\[x_{j+1}'=f(x_j',a_j').\]
	Definimos también 
    $C_N(x,\pi'):=c_N(x)$ 
    para cada $x\in X$. 
    Usando {\it inducción hacia atrás}, vamos a demostrar que
    \begin{equation}\label{DPalgorIneq}
    	C_k(x,\pi')\geq J_k(x) \quad \forall \ x\in X, \ k=N,N-1,\ldots,0,
	\end{equation}
	con igualdad si $\pi'=\hat{\pi}$. 
    Para $k=N$, \eqref{DPalgorIneq} se cumple con igualdad. 
    Supongamos que $C_{k+1}(y,\pi')\geq J_{k+1}(y)$ para todo $y\in X$, 
    con igualdad si $\pi'=\hat{\pi}$. Entonces
    \begin{eqnarray}
		C_k(x,\pi') & = & c_k(x,a_k')+ C_{k+1}(f(x,a_{k}'),\pi') \nonumber\\
            & \geq & c_k(x,a_k')+ J_{k+1}(f(x,a_{k}'))\label{IneqBaIndHyp}\\
    	& \geq & c_k(x,h_k(x)) + J_{k+1}(f(x,h_k(x))) \label{EquSelec}\\
    	&   =  & J_k(x) \nonumber.
	\end{eqnarray}
	La desigualdad \eqref{IneqBaIndHyp} se tiene por la hipótesis de inducción, 
	con $y=f(x,a_k')$, mientras que \eqref{EquSelec} se sigue de 
  \eqref{SelectorHyp}. Más aún, notemos que \eqref{EquSelec} y 
	\eqref{SelectorHyp} se cumplen con 	igualdad si $\pi'=\hat{\pi}$. Esto 
	demuestra que la función $J_0$ obtenida 	en el último paso del APD coincide 
	con la función de valor $v$.
\end{proof}

\begin{obs} 
		El algoritmo de PD también funciona para resolver problemas de 
	maximización. En tal caso, hay que cambiar $\min$ por $\max$ en \eqref{DPA}. 
	En la literatura sobre optimización, tanto teórica como computacional, es más 
	común trabajar con problemas de minimización que de maximización. 
\end{obs}%\todo{presetnar comno remark}

\begin{ejem}[Decisiones de ahorro] 
		Supongamos que Ricardo % Richard Lusting
	ha ganado el premio mayor de la Lotería Nacional y decide 
	meter su dinero al banco que le ofrece una tasa de interés anual $r$. Al 
	inicio del año $k$ decide retirar $a_k$ pesos para sus gastos y planea 
	repetir este proceso $N$ veces, es decir, $k=0,1,\ldots,N-1$. Si $x_k$ 
	denota la cantidad de dinero al inicio del año $k$, entonces la ecuación
	\begin{equation}\label{DynConInv}
		x_{k+1}=(1+r)(x_k-a_k), \quad k=0,1,\ldots,N-1.
	\end{equation}
	describe cómo va cambiando la fortuna de Ricardo en función de los retiros 
que 
	haga. {\it Utility theory}, una empresa de consultoría, le recomienda a 
	Ricardo que escoja $\{a_0,\ldots,a_{N-1}\}$ de tal manera que maximice
	\begin{equation}\label{ObjFuConInv}
      \beta^N(x_N)^{1-\gamma}+\sum_{k=0}^{N-1}\beta^k(a_k)^{1-\gamma}.
	\end{equation}
	La cantidad final $x_N$ será heredada a sus descendientes. Los parámetros 
  $\beta,\gamma\in(0,1)$ fueron estimados por {\it Utility theory} 
  (ver \cite{Fishburn}).
	Usando el APD encontramos que cada función $J_k$ es de la forma 
  $J_k(x) = A_k\beta^kx^{1-\gamma}$, donde $A_N=1$ y para $k=N-1,\ldots,0,$  
  \[ A_k=[1+((1+r)\beta A_{k+1})^{1/\gamma}]^{\gamma}.\]
		La política óptima está dada por 
  \[ 
		 h_k(x)=\frac{x}{A_{k}^{1/\gamma}},\quad k=0,\ldots,N-1.  
	\]
\end{ejem}
\paragraph{determinista, horizonte finito}
\paragraph{Proof}
%\paragraph{determinista, horizonte finito}
%\paragraph{Proof}
\todo[caption={short for LoTds}]{
		Modificar grafica para representar la región de factible, plotear con 
		puntos el control
	}